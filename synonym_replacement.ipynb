{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# From https://github.com/TrustAI/testRNN/blob/master/src/eda.py\n",
    "def get_synonyms(word):\n",
    "\tsynonyms = set()\n",
    "\tfor syn in wordnet.synsets(word):\n",
    "\t\tfor l in syn.lemmas():\n",
    "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "\t\t\tsynonyms.add(synonym)\n",
    "\tif word in synonyms:\n",
    "\t\tsynonyms.remove(word)\n",
    "\treturn list(synonyms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n9/hqzs1jgx23s1dzqhq1ccrbtm0000gn/T/ipykernel_9329/3149698356.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# WordNet synonyms are VERY unreliable:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mget_synonyms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'water'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/n9/hqzs1jgx23s1dzqhq1ccrbtm0000gn/T/ipykernel_9329/637342096.py\u001B[0m in \u001B[0;36mget_synonyms\u001B[0;34m(word)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_synonyms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m         \u001B[0msynonyms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0msyn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mwordnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msynsets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msyn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlemmas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m                         \u001B[0msynonym\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"_\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"-\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, attr)\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m         \u001B[0;31m# This looks circular, but its not, since __load() changes our\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0;31m# __class__ to something new:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0;31m# Load the corpus.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m         \u001B[0mcorpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__reader_cls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m         \u001B[0;31m# This is where the magic happens!  Transform ourselves into\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, omw_reader)\u001B[0m\n\u001B[1;32m   1193\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1194\u001B[0m         \u001B[0;31m# Load the indices for lemmas and synset offsets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1195\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load_lemma_pos_offset_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1197\u001B[0m         \u001B[0;31m# load the exception file data into memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\u001B[0m in \u001B[0;36m_load_lemma_pos_offset_map\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1305\u001B[0m             \u001B[0;31m# parse each line of the file (ignoring comment lines)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1306\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"index.%s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0msuffix\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1307\u001B[0;31m                 \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1308\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1309\u001B[0m                         \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/data.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1151\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1152\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1154\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mnext\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m         \u001B[0;34m\"\"\"Return the next decoded line from the underlying stream.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1145\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1146\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1147\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mreadline\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1098\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1099\u001B[0;31m             \u001B[0mstartpos\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbytebuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1100\u001B[0m             \u001B[0mnew_chars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreadsize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# WordNet synonyms are VERY unreliable:\n",
    "\n",
    "get_synonyms('water')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_synonyms('want')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:loading projection weights from news_vectors.bin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/n9/hqzs1jgx23s1dzqhq1ccrbtm0000gn/T/ipykernel_9329/2893365139.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mword2vec_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'news_vectors.bin'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mvectors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mKeyedVectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_word2vec_format\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword2vec_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mload_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[0m\n\u001B[1;32m   1627\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1628\u001B[0m         \"\"\"\n\u001B[0;32m-> 1629\u001B[0;31m         return _load_word2vec_format(\n\u001B[0m\u001B[1;32m   1630\u001B[0m             \u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfvocab\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfvocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbinary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0municode_errors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0municode_errors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1631\u001B[0m             \u001B[0mlimit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatatype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mno_header\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mno_header\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_load_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[0m\n\u001B[1;32m   1970\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1971\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1972\u001B[0;31m             _word2vec_read_binary(\n\u001B[0m\u001B[1;32m   1973\u001B[0m                 \u001B[0mfin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcounts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvector_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatatype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0municode_errors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary_chunk_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1974\u001B[0m             )\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_word2vec_read_binary\u001B[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size)\u001B[0m\n\u001B[1;32m   1865\u001B[0m         \u001B[0mnew_chunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbinary_chunk_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1866\u001B[0m         \u001B[0mchunk\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnew_chunk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1867\u001B[0;31m         processed_words, chunk = _add_bytes_to_kv(\n\u001B[0m\u001B[1;32m   1868\u001B[0m             kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors)\n\u001B[1;32m   1869\u001B[0m         \u001B[0mtot_processed_words\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mprocessed_words\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_add_bytes_to_kv\u001B[0;34m(kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors)\u001B[0m\n\u001B[1;32m   1850\u001B[0m         \u001B[0;31m# Some binary files are reported to have obsolete new line in the beginning of word, remove it\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1851\u001B[0m         \u001B[0mword\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\n'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1852\u001B[0;31m         \u001B[0mvector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfrombuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moffset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mi_vector\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvector_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mREAL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1853\u001B[0m         \u001B[0m_add_word_to_kv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcounts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvector\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1854\u001B[0m         \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mi_vector\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mbytes_per_vector\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = 'news_vectors.bin'\n",
    "vectors = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The name of the constellation is Latin for lion, and to the ancient Greeks it was the Nemean Lion killed by the mythical Greek hero Heracles.']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import spacy\n",
    "from dev_data import texts as dev_texts\n",
    "import numpy as np\n",
    "\n",
    "nlp_spacy = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_sentences(text):\n",
    "    \"\"\"\n",
    "    Use spaCy for sentence segmentation\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    doc = nlp_spacy(text)\n",
    "    for sent in doc.sents:\n",
    "        sentences.append(str(sent))\n",
    "    return np.array(sentences)\n",
    "\n",
    "input_sentences = get_sentences(dev_texts[1][0])[:10]\n",
    "#input_sentence = \"They were there to enjoy us and they were there to pray for us.\"\n",
    "#\n",
    "# model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text, num_return_sequences, num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text\n",
    "\n",
    "print(dev_texts[1][0])\n",
    "print(get_response(dev_texts[1][0], 40, 10))\n",
    "\n",
    "# for input_sentence in input_sentences:\n",
    "#     generated_sentence = get_response(input_sentence, 10, 10)\n",
    "#     print('----------')\n",
    "#     print('ORIGINAL:')\n",
    "#     print(input_sentence)\n",
    "#     print('PARAPHRASED:')\n",
    "#     print(generated_sentence)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}